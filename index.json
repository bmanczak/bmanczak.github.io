[{"content":"TL;DR: A simple CLI tool to convert AI chat share links into clean, copy-pasteable conversation formats for easy context switching between different AI tools.\nFind yourself switching between different AI chats (ChatGPT, Claude, Grok) and AI apps (e.g. Cursor)? ðŸ‘€\nI do! I built myself a tool to make passing whole conversations as context between them super easy. It came up in a few conversations as useful for other people so sharing it widely ðŸ¤—\nYou just get the conversation share link, type renderchat \u0026lt;share_link\u0026gt; in your terminal and webpage with ready to copy past conversation pops up.\nYou can find it here: renderchat\nAnd here\u0026rsquo;s a quick demo:\nThis is directly inspired by Andrej Karpathy\u0026rsquo;s rendergit repository which I also use often!\n","permalink":"https://bmanczak.github.io/posts/renderchat-just-show-me-conversation/","summary":"\u003cp\u003eTL;DR: A simple CLI tool to convert AI chat share links into clean, copy-pasteable conversation formats for easy context switching between different AI tools.\u003c/p\u003e","title":"renderchat: just show me the conversation"},{"content":" I\u0026rsquo;m a lead research engineer at Dynamo AI (YC 22). I work on (synthetic) data flywheels, evaluations, and training (SFT / RL), all focused on creating efficient and aligned custom guardrailing and judge models. What makes it hard (and thus fun) is that the objectives are subjective, under-specified in natural language and require iterative human-model alignment through extensive evals.\nBefore joining Dynamo I worked in RL for Combinatorial Optimization and Code Generation teams at Qualcomm AI Research in Amsterdam. I studied Artifical Intelligence at the Univeristy of Amsterdam, specializing in Reinforcement Learning where I spent 9 months at Amsterdam Machine Learning lab with prof. Herke van Hoof.\nProjects I am most proud of: Built Dynamo\u0026rsquo;s output guardrail offering and team from the ground up into a mature, high-demand product. I touched every part of the stack, from interacting with PMs on definig evalaution sets, setting up annotation procedures and feedback loops, synthetic data generation, training, post-training interventions for more customizability and efficient inference. The product is used be a few Fortune 500 companies (1, 2, 3) to safeguard their AI deployments Togeher with my team at Qualcomm we achieved SOTA on The Abstraction and Reasoning Challenge (ARC) with a ~ 220M language model by combining hindsight relabeling of erronoues program and learning from prioritized hinsight reply (ICML 24\u0026rsquo; paper). Despite being ~ a dead end I am also proud of our attempt to use MCTS as a neurally-guided search language model decoding method to provide natural curriculm for learning to write simple programs in zero human data regime (ICML 24\u0026rsquo; workshop paper) Demonstrated that (hierarchical) RL can mitiagte congestion in power grids up to 6x more efficiently than a physics based simulator and that hierarchical policies can outperform the non-hierarchical ones. Wrote a paper about it. Outside of work, I love endurance sports and science behind achieving peak human perfromance. I swim, bike, run, and like Middle Distance Training (70.3 IM) the most. Have a sub-10 Ironman race under the belt, want to do a sub 9 at some point. I lack time for other sports but I also do enjoy them: despite failing at learning surfing, I am not giving up :)\nSometimes I write about stuff; you can read it here: /posts/.\nContact: if you\u0026rsquo;d like to chat about AI, go for a bike ride or grab coffee send me a DM on X / LinkedIn / Strava.\n","permalink":"https://bmanczak.github.io/about/","summary":"\u003cimg alt=\"Blazej Manczak\" src=\"/images/profile-photo.jpg\" style=\"width: 250px; height: 250px; border-radius: 50%; object-fit: cover; display: block; margin: 0 auto 20px auto;\"\u003e\n\u003cp\u003eI\u0026rsquo;m a lead research engineer at \u003ca href=\"https://dynamo.ai/\"\u003eDynamo AI (YC 22)\u003c/a\u003e. I work on (synthetic) data flywheels, evaluations, and training (SFT / RL), all focused on creating efficient and aligned custom guardrailing and judge models. What makes it hard (and thus fun) is that the objectives are subjective, under-specified in natural language and require iterative human-model alignment through extensive evals.\u003c/p\u003e","title":"About"}]