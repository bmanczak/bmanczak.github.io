---
date: "2025-05-12T15:23:52+02:00"
draft: false
title: "About"
---

<img alt="Blazej Manczak" src="/images/profile-photo.jpg" style="width: 250px; height: 250px; border-radius: 50%; object-fit: cover; display: block; margin: 0 auto 20px auto;">

I'm a lead research engineer at [Dynamo AI (YC 22)](https://dynamo.ai/). I work on (synthetic) data flywheels, evaluations, and training (SFT / RL), all focused on creating efficient and aligned custom guardrailing and judge models. What makes it hard (and thus fun) is that the objectives are subjective, under-specified in natural language and require iterative human-model alignment through extensive evals.

Before joining Dynamo I worked in RL for Combinatorial Optimization and Code Generation teams at Qualcomm AI Research in Amsterdam. I studied Artifical Intelligence at the Univeristy of Amsterdam, specializing in Reinforcement Learning where I spent 9 months at [Amsterdam Machine Learning](https://amlab.science.uva.nl/) lab with prof. Herke van Hoof.

### Projects I am most proud of:

- Built Dynamo's output guardrail offering and team from the ground up into a mature, high-demand product. I touched every part of the stack, from interacting with PMs on definig evalaution sets, setting up annotation procedures and feedback loops, synthetic data generation, training, post-training interventions for more customizability and efficient inference. The product is used be a few Fortune 500 companies ([1](https://www.experianplc.com/newsroom/press-releases/dynamo-ai-helps-accelerate-experian-s-safe-and-secure-genai-adop), [2](https://dynamo.ai/blog/itochu-techno-solutions-joins-forces-with-dynamo-ai-to-strengthen-generative-ai-compliance-and-reliability-for-financial-institutions), [3](https://dynamo.ai/blog)) to safeguard their AI deployments
- Togeher with my team at Qualcomm we achieved SOTA on The Abstraction and Reasoning Challenge (ARC) with a ~ 220M language model by combining hindsight relabeling of erronoues program and learning from prioritized hinsight reply (ICML 24' [paper](https://arxiv.org/abs/2402.04858)). Despite being ~ a dead end I am also proud of our attempt to use MCTS as a neurally-guided search language model decoding method to provide natural curriculm for learning to write simple programs in zero human data regime (ICML 24' workshop [paper](<https://openreview.net/forum?id=SA2zPf03zQ&referrer=%5Bthe%20profile%20of%20Blazej%20Manczak%5D(%2Fprofile%3Fid%3D~Blazej_Manczak1)>))
- Demonstrated that (hierarchical) RL can mitiagte congestion in power grids up to 6x more efficiently than a physics based simulator and that hierarchical policies can outperform the non-hierarchical ones. Wrote a [paper](https://arxiv.org/abs/2311.02129) about it.

Outside of work, I love endurance sports and science behind achieving peak human perfromance. I swim, bike, run, and like Middle Distance Training (70.3 IM) the most. Have a sub-10 Ironman race under the belt, want to do a sub 9 at some point. I lack time for other sports but I also do enjoy them: despite failing at learning surfing, I am not giving up :)

Sometimes I write about stuff; you can read it here: [/posts/](/posts/).

**Contact:** if you'd like to chat about AI, go for a bike ride or grab coffee send me a DM on X / LinkedIn / Strava.
